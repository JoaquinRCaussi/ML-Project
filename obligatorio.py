# -*- coding: utf-8 -*-
"""Obligatorio.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BQ0GQIVec9wy7dS_0qP4nZ7SgN_MSW9n

### **Obligatorio Machine Learning**

### Imports
"""

# Encadenar iterables
from itertools import chain

# Proporciona una barra de progreso rápida
from tqdm import tqdm

# Selección aleatoria de una lista sin repetición
from random import sample

# Interfaz para hacer gráficos y visualizaciones
import matplotlib.pyplot as plt

# Computación científica
import numpy as np

# Manipulación de datos
import pandas as pd

# Para guardar y cargar modelos
from joblib import dump, load

# Extraer parches (pequeños subconjuntos de imágenes) de imágenes
from sklearn.feature_extraction.image import PatchExtractor

# data: conjunto de datos de muestra y funciones de carga
# color: convertir imágenes entre espacios de color
# feature: funciones para identificar y extraer características de imágenes
from skimage import data, color, feature

# Cambiar el tamaño de una imagen
from skimage.transform import resize, rescale

# Descarga y carga en memoria un conjunto de datos de imágenes de caras de personas famosas
from sklearn.datasets import fetch_lfw_people

# Modelos
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

# Validación cruzada
from sklearn.model_selection import cross_validate
from sklearn.model_selection import StratifiedKFold

# Matriz de confusión
from sklearn.metrics import confusion_matrix

# La curva ROC
from sklearn.metrics import roc_curve , auc

# Métricas custom
from sklearn.metrics import make_scorer

from google.colab import drive
drive.mount('/content/drive')

"""# Funciones auxiliares


"""

# Función para extraer porciones de una imagen
def extract_patches(img, N, scale=1.0, patch_size=(62,47)):
    # Calcula el tamaño del parche extraído basado en el factor de escala dado
    H = img.shape[0]
    W = img.shape[1]
    H_patch = min(H , int(scale * patch_size[0]))
    W_patch = min(W , int(scale * patch_size[1]))
    extracted_patch_size = (H_patch, W_patch)

    # Inicializa un objeto PatchExtractor con el tamaño de parche calculado,
    # el número máximo de parches, y una semilla de estado aleatorio
    extractor = PatchExtractor(patch_size=extracted_patch_size, max_patches=N, random_state=0)

    # Extrae parches de la imagen dada
    # img[np.newaxis] se utiliza la entrada de PatchExtractor es un conjunto de imágenes
    patches = extractor.transform(img[np.newaxis])

    # Si el factor de escala no es 1, redimensiona cada parche extraído
    # al tamaño del parche original
    if scale != 1:
        patches = np.array([resize(patch, patch_size) for patch in patches])

    # Devuelve la lista de parches extraídos (y posiblemente redimensionados)
    return patches

def non_max_suppression(indices, Ni, Nj, overlapThresh):
    # Si no hay rectángulos, regresar una lista vacía
    if len(indices) == 0:
        return []

    # Si las cajas son enteros, convertir a flotantes
    if indices.dtype.kind == "i":
        indices = indices.astype("float")

    # Inicializar la lista de índices seleccionados
    pick = []

    # Tomar las coordenadas de los cuadros
    x1 = np.array([indices[i,0] for i in range(indices.shape[0])])
    y1 = np.array([indices[i,1] for i in range(indices.shape[0])])
    x2 = np.array([indices[i,0]+Ni for i in range(indices.shape[0])])
    y2 = np.array([indices[i,1]+Nj for i in range(indices.shape[0])])

    # Calcula el área de los cuadros y ordena los cuadros
    area = (x2 - x1 + 1) * (y2 - y1 + 1)
    idxs = np.argsort(y2)

    # Mientras todavía hay índices en la lista de índices
    while len(idxs) > 0:
        # Toma el último índice de la lista y agrega el índice a la lista de seleccionados
        last = len(idxs) - 1
        i = idxs[last]
        pick.append(i)

        # Encontrar las coordenadas (x, y) más grandes para el inicio de la caja y las coordenadas (x, y) más pequeñas para el final de la caja
        xx1 = np.maximum(x1[i], x1[idxs[:last]])
        yy1 = np.maximum(y1[i], y1[idxs[:last]])
        xx2 = np.minimum(x2[i], x2[idxs[:last]])
        yy2 = np.minimum(y2[i], y2[idxs[:last]])

        # Calcula el ancho y alto de la caja
        w = np.maximum(0, xx2 - xx1 + 1)
        h = np.maximum(0, yy2 - yy1 + 1)

        # Calcula la proporción de superposición
        overlap = (w * h) / area[idxs[:last]]

        # Elimina todos los índices del índice de lista que tienen una proporción de superposición mayor que el umbral proporcionado
        idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlapThresh)[0])))

    # Devuelve solo las cajas seleccionadas
    return indices[pick].astype("int")

# True Positive Rate
def tpr_scorer(clf, X, y):
  y_pred = clf.predict(X)
  cm = confusion_matrix(y, y_pred)
  tpr = cm[1,1]/(cm[1,1]+cm[1,0])
  return tpr

# False Positive Rate
def fpr_scorer(clf, X, y):
  y_pred = clf.predict(X)
  cm = confusion_matrix(y, y_pred)
  fpr = cm[0,1]/(cm[0,0]+cm[0,1])
  return fpr

# Define una función para realizar una ventana deslizante (sliding window) sobre una imagen.
def sliding_window(img,
                   patch_size=(62,47),  # Define el tamaño del parche (patch) basado en el primer parche positivo por defecto
                   istep=2,  # Paso de desplazamiento en la dirección i (verticalmente)
                   jstep=2,  # Paso de desplazamiento en la dirección j (horizontalmente)
                   scale=1.0):  # Factor de escala para ajustar el tamaño del parche

    # Calcula las dimensiones Ni y Nj del parche ajustadas por el factor de escala.
    Ni, Nj = (int(scale * s) for s in patch_size)

    # Itera a lo largo de la imagen en la dirección i
    for i in range(0, img.shape[0] - Ni, istep):
        # Itera a lo largo de la imagen en la dirección j
        for j in range(0, img.shape[1] - Ni, jstep):

            # Extrae el parche de la imagen usando las coordenadas actuales i, j.
            patch = img[i:i + Ni, j:j + Nj]

            # Si el factor de escala es diferente de 1, redimensiona el parche al tamaño original del parche.
            if scale != 1:
                patch = resize(patch, patch_size)

            # Usa yield para devolver las coordenadas actuales y el parche.
            # Esto convierte la función en un generador.
            yield (i, j), patch

"""# Armar el Dataset

Importamos el dataset LFW con los rostros los cuales consideraremos como etiquetas positivas
"""

# Cargamos el dataset
faces = fetch_lfw_people()
positive_patches = faces.images
positive_patches.shape

"""Armamos los fondos que tomameros como etiquetas negativas. Estas las conseguimos desde imagenes nuestras y algunas tomadas de sklearn

"""

imgs = ['camera',
        'text',
        'coins',
        'moon',
        'page',
        'clock',
        'immunohistochemistry',
        'chelsea',
        'coffee',
        'hubble_deep_field'
        ]

backgrounds = []
for name in imgs:
    img = getattr(data, name)()
    if len(img.shape) == 3 and img.shape[2] == 3:  # Chequeamos si la imagen es RGB
        img = color.rgb2gray(img)
    backgrounds.append(img)

# Imagenes caseras adicionales
for i in range(31):
    filename = f'/content/drive/MyDrive/{i}.jpg'
    img = plt.imread(filename)
    img = color.rgb2gray(img)
    backgrounds.append(img)

print(len(backgrounds))

model = LogisticRegression(penalty='l2',C=1, max_iter=1000)
resolution = 1
scales = [0.5,1,2,4,8]
proportion = 10
num_patches = int((proportion * len(positive_patches))/(len(scales) * len(backgrounds)))
orientations = 3
pixels_per_cell = (12, 12)
cells_per_block = (3, 3)

model_name = str(model)
experiment_name = model_name
experiment_name += '_R_' + str(resolution)
experiment_name += '_S_' + str(scales)
experiment_name += '_P_' + str(proportion)
experiment_name += '_O_' + str(orientations)
experiment_name += '_C_' + str(pixels_per_cell)
experiment_name += '_B_' + str(cells_per_block)

print(experiment_name)

# Tamaño de las imágenes de rostros
positive_patches = np.array(
    [rescale(positive_patches[i],resolution)
    for i in tqdm(range(len(positive_patches)))]
    )
size = positive_patches[0].shape
print(size)

# Podemos chequear las escalas que hemos elegido
im = 0  # Elegir un indice entre 0 y len(backgrounds)-1
fig, ax = plt.subplots(1,len(scales) + 1,figsize=(20,4))
for i in range(len(scales)):
  ax[i].imshow(extract_patches(backgrounds[im], 1, scales[i]).reshape((62,47)),cmap='gray')

ax[len(scales)].imshow(backgrounds[im],cmap='gray')
plt.tight_layout()
plt.show()

# Extraemos las imágenes de fondo
negative_patches = np.vstack(
    [extract_patches(im, num_patches, scale)
    for im in tqdm(backgrounds, desc='Procesando imágenes')
    for scale in scales]
    )
negative_patches.shape

# Armamos la matriz de features y el vector de etiquetas
X = np.array(
    [feature.hog(image=im,
                 orientations=orientations,
                 pixels_per_cell=pixels_per_cell,
                 cells_per_block=cells_per_block)
    for im in tqdm(chain(positive_patches, negative_patches))]
    )
y = np.zeros(X.shape[0])
y[:positive_patches.shape[0]] = 1

X.shape

y.shape

"""# Modelos

## 1) Regresión Logistica
"""

# Diccionario de scores
scoring = {'acc': 'accuracy',
           'prec': 'precision_macro',
           'rec': 'recall_macro',
           'f1':'f1_macro',
           'b_acc': 'balanced_accuracy',
           'auc': 'roc_auc',
           'tpr': tpr_scorer,
           'fpr': fpr_scorer
           }

# Validación cruzada
scores = cross_validate(model,
                        X,
                        y,
                        verbose=2,
                        scoring=scoring,
                        cv=5)

# Podemos pasarlo a data frame para mejor manejo
df_scores = pd.DataFrame(scores)
df_scores

# Nos importan mas los promedios
results = pd.DataFrame(
    data={
        'TIME': scores['fit_time'],
        'ACCURACY': scores['test_acc'],
        'PRECISION': scores['test_prec'],
        'RECALL': scores['test_rec'],
        'F1': scores['test_f1'],
        'B_ACCURACY': scores['test_b_acc'],
        'AUC': scores['test_auc'],
        'TPR': scores['test_tpr'],
        'FPR': scores['test_fpr'],
    }
).mean()

print(results)

# Podemos guardarlo en un archivo de texto
results.to_csv(experiment_name + '.csv', header=False)

n_splits = 5
cv = StratifiedKFold(n_splits=n_splits)

thrs = []
tprs = []
fprs = []

fig, ax = plt.subplots(figsize=(4, 4))
for fold, (train, test) in enumerate(cv.split(X, y)):
    model.fit(X[train], y[train])
    y_pred = model.predict_proba(X[test])
    y_pred = y_pred[:, 1]
    fpr, tpr, thresholds = roc_curve(y[test], y_pred)
    gmean = np.sqrt(tpr * (1 - fpr))
    index = np.argmax(gmean)
    thresholdOpt = round(thresholds[index], ndigits = 4)
    fprOpt = round(fpr[index], ndigits = 4)
    tprOpt = round(tpr[index], ndigits = 4)

    thrs.append(thresholdOpt)
    tprs.append(tprOpt)
    fprs.append(fprOpt)

    ax.step(
        fpr,
        tpr,
        label=f'Fold {fold}',
        lw=1,
        alpha=1,
    )

    ax.plot(
        fprOpt,
        tprOpt,
        marker = 'o'
    )

print(f'Umbrales óptimos:\n {thrs}')
print(f'Mejor umbral promedio: {np.mean(thrs)}')
print(f'Desvío umbral: {np.std(thrs)}')
print(f'FPR promedio: {np.mean(fprs)}, TPR promedio: {np.mean(tprOpt)}')

with open(experiment_name + 'Umbral.txt', 'w') as f:
    f.write('Mejor umbral promedio: ' + str(np.mean(thrs)))
    f.write('\n')
    f.write('FPR promedio: ' + str(np.mean(fprs)) + ' TPR promedio: ' + str(np.mean(tprOpt)))

ax.set(
    xlim=[-0.05, 1.05],
    ylim=[-0.05, 1.05],
    xlabel="False Positive Rate",
    ylabel="True Positive Rate",
    title=f"Curvas ROC para cada fold",
)
ax.axis("square")
ax.legend(loc="lower right")
plt.show()

"""## 2) Arbol de decisión"""

from sklearn.model_selection import train_test_split

# X e y son las características e etiquetas, respectivamente
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
from sklearn.tree import DecisionTreeClassifier

# Inicializamos el clasificador de árbol de decisión
clfdt = DecisionTreeClassifier(random_state=42)

# Entrenamos el modelo
clfdt.fit(X_train, y_train)
dump(clfdt, 'decision_tree_model1.pkl')

# evaluamos el modelo
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Predicciones en el conjunto de prueba
y_pred = clf.predict(X_test)

# Métricas de evaluación
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

from sklearn.model_selection import cross_validate
import pandas as pd

# Diccionario de métricas para la validación cruzada
scoring = {
    'acc': 'accuracy',
    'prec': 'precision_macro',
    'rec': 'recall_macro',
    'f1': 'f1_macro',
    'b_acc': 'balanced_accuracy'
}

# Ejecutando la validación cruzada
scores = cross_validate(clf, X, y, scoring=scoring, cv=5, return_train_score=False)

# Convertir los resultados a DataFrame para un mejor manejo
df_scores = pd.DataFrame(scores)
print(df_scores)

# Calculando los promedios de las métricas de validación cruzada
results = pd.DataFrame({
    'TIME': scores['fit_time'],
    'ACCURACY': scores['test_acc'],
    'PRECISION': scores['test_prec'],
    'RECALL': scores['test_rec'],
    'F1': scores['test_f1'],
    'B_ACCURACY': scores['test_b_acc']
}).mean()

# Imprimiendo los resultados
print(results)

from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_curve, auc
import numpy as np
import matplotlib.pyplot as plt

# Suponiendo que 'clf' es tu modelo de árbol de decisión ya entrenado
n_splits = 5
cv = StratifiedKFold(n_splits=n_splits)

thrs = []
tprs = []
fprs = []
aucs = []  # Para almacenar las puntuaciones AUC de cada fold

fig, ax = plt.subplots(figsize=(4, 4))
for fold, (train, test) in enumerate(cv.split(X, y)):
    # Entrenamos el modelo con los datos de entrenamiento de la partición actual
    clf.fit(X[train], y[train])
    # Predecimos las probabilidades en el conjunto de prueba de la partición actual
    y_pred = clf.predict_proba(X[test])[:, 1]
    fpr, tpr, thresholds = roc_curve(y[test], y_pred)
    roc_auc = auc(fpr, tpr)  # Calculamos el AUC
    aucs.append(roc_auc)  # Almacenamos el AUC

    # Encontramos el umbral óptimo
    gmean = np.sqrt(tpr * (1 - fpr))
    index = np.argmax(gmean)
    thresholdOpt = round(thresholds[index], ndigits=4)
    fprOpt = round(fpr[index], ndigits=4)
    tprOpt = round(tpr[index], ndigits=4)

    # Almacenamos los valores óptimos
    thrs.append(thresholdOpt)
    tprs.append(tprOpt)
    fprs.append(fprOpt)

    # Graficamos la curva ROC para este fold
    ax.plot(fpr, tpr, lw=1, alpha=0.3, label=f'ROC fold {fold} (AUC = {roc_auc:.2f})')
    ax.plot(fprOpt, tprOpt, 'o', markersize=5)

# Configuramos el gráfico
ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Suerte', alpha=.8)
ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], title="Curva ROC")
ax.legend(loc="lower right")
plt.xlabel("Tasa de Falsos Positivos")
plt.ylabel("Tasa de Verdaderos Positivos")
plt.show()

# Imprimimos los resultados
print(f'Umbrales óptimos:\n {thrs}')
print(f'Mejor umbral promedio: {np.mean(thrs)}')
print(f'Desviación estándar del umbral: {np.std(thrs)}')
print(f'FPR promedio: {np.mean(fprs)}, TPR promedio: {np.mean(tprs)}')
print(f'AUC promedio: {np.mean(aucs)}')  # Imprimimos también el AUC promedio

test_image = plt.imread('/content/drive/MyDrive/Central.jpg')
test_image = color.rgb2gray(test_image)
test_image = rescale(test_image,0.5)
test_image.shape

# Visualizamos la imagen
# Buscamos la escala de los rostros
fig, ax = plt.subplots()
ax.imshow(test_image, cmap='gray')

scale = 0.6
Ni, Nj = (int(scale * s) for s in size)

ax.add_patch(plt.Rectangle((0, 0), Nj, Ni, edgecolor='red', alpha=1, lw=1, facecolor='none'))
plt.show()

# Utiliza la función de ventana deslizante en una imagen de prueba.
# zip(*...) toma las tuplas generadas y las descompone en índices y parches.
indices, patches = zip(*sliding_window(test_image, scale=scale))

# Calcula las características HOG para cada parche y las almacena en un array.
patches_hog = np.array([feature.hog(patch,
                                    orientations=orientations,
                                    pixels_per_cell=pixels_per_cell,
                                    cells_per_block=cells_per_block) for patch in patches])

# Muestra la forma del array de características HOG.
patches_hog.shape

# Predicción
clf_dt = load('decision_tree_model1.pkl')
labels = clf_dt.predict(patches_hog).astype(int)
labels.sum()

Ni, Nj = (int(scale*s) for s in size)
indices = np.array(indices)
detecciones = indices[labels == 1]
detecciones = non_max_suppression(np.array(detecciones),Ni,Nj, 0.3)

# Visualizamos las detecciones
fig, ax = plt.subplots()
ax.imshow(test_image, cmap='gray')
ax.axis('off')

for i, j in detecciones:
    ax.add_patch(plt.Rectangle((j, i), Nj, Ni, edgecolor='red',
                               alpha=1, lw=1, facecolor='none'))

plt.savefig('test_centralDecisionTree.png')



"""## 3) Gradient boosting

"""

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from joblib import dump

# Asumiendo que X e y son tus características y etiquetas, respectivamente
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicializamos el clasificador de Gradient Boosting con árboles de profundidad 1
clf_gb = GradientBoostingClassifier(max_depth=1, random_state=42)

# Entrenamos el modelo
clf_gb.fit(X_train, y_train)
dump(clf_gb, 'gradient_boosting_model.pkl')

# Predicciones en el conjunto de prueba
y_pred = clf_gb.predict(X_test)

# Métricas de evaluación
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

# Diccionario de métricas para la validación cruzada
scoring = {
    'acc': 'accuracy',
    'prec': 'precision_macro',
    'rec': 'recall_macro',
    'f1': 'f1_macro',
    'b_acc': 'balanced_accuracy'
}

# Ejecutando la validación cruzada
scores = cross_validate(clf_gb, X, y, scoring=scoring, cv=5, return_train_score=False)
df_scores = pd.DataFrame(scores)
print(df_scores)
# Calculando los promedios de las métricas de validación cruzada
results = df_scores.mean()
print(results)

# Configuración para la curva ROC
n_splits = 5
cv = StratifiedKFold(n_splits=n_splits)

thrs = []
tprs = []
fprs = []
aucs = []  # Para almacenar las puntuaciones AUC de cada fold

fig, ax = plt.subplots(figsize=(4, 4))
for fold, (train, test) in enumerate(cv.split(X, y)):
    # Entrenamos el modelo con los datos de entrenamiento de la partición actual
    clf_gb.fit(X[train], y[train])
    # Predecimos las probabilidades en el conjunto de prueba de la partición actual
    y_pred = clf_gb.predict_proba(X[test])[:, 1]
    fpr, tpr, thresholds = roc_curve(y[test], y_pred)
    roc_auc = auc(fpr, tpr)  # Calculamos el AUC
    aucs.append(roc_auc)  # Almacenamos el AUC

    # Encontramos el umbral óptimo
    gmean = np.sqrt(tpr * (1 - fpr))
    index = np.argmax(gmean)
    thresholdOpt = round(thresholds[index], ndigits=4)
    fprOpt = round(fpr[index], ndigits=4)
    tprOpt = round(tpr[index], ndigits=4)

    # Almacenamos los valores óptimos
    thrs.append(thresholdOpt)
    tprs.append(tprOpt)
    fprs.append(fprOpt)

    # Graficamos la curva ROC para este fold
    ax.plot(fpr, tpr, lw=1, alpha=0.3, label=f'ROC fold {fold} (AUC = {roc_auc:.2f})')
    ax.plot(fprOpt, tprOpt, 'o', markersize=5)

# Configuramos el gráfico
ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Suerte', alpha=.8)
ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], title="Curva ROC de Gradient Boosting")
ax.legend(loc="lower right")
plt.xlabel("Tasa de Falsos Positivos")
plt.ylabel("Tasa de Verdaderos Positivos")
plt.show()

# Imprimimos los resultados
print(f'Umbrales óptimos:\n {thrs}')
print(f'Mejor umbral promedio: {np.mean(thrs)}')
print(f'Desviación estándar del umbral: {np.std(thrs)}')
print(f'FPR promedio: {np.mean(fprs)}, TPR promedio: {np.mean(tprs)}')
print(f'AUC promedio: {np.mean(aucs)}')  # Imprimimos también el AUC promedio

# Predicción
clf_dt = load('gradient_boosting_model.pkl')
labels = clf_dt.predict(patches_hog).astype(int)
labels.sum()

Ni, Nj = (int(scale*s) for s in size)
indices = np.array(indices)
detecciones = indices[labels == 1]
detecciones = non_max_suppression(np.array(detecciones),Ni,Nj, 0.3)

# Visualizamos las detecciones
fig, ax = plt.subplots()
ax.imshow(test_image, cmap='gray')
ax.axis('off')

for i, j in detecciones:
    ax.add_patch(plt.Rectangle((j, i), Nj, Ni, edgecolor='red',
                               alpha=1, lw=1, facecolor='none'))

plt.savefig('test_centralGradientBoosting.png')

"""## 4) Random Forest"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicializar el modelo Random Forest
clf_rf1 = RandomForestClassifier(n_estimators=10, random_state=42)
# Entrenar el modelo
clf_rf1.fit(X_train, y_train)
dump(clf_rf1, 'random_forest_model1.pkl')

# Evaluar el modelo en el conjunto de prueba
y_pred = clf_rf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

# Diccionario de métricas para la validación cruzada
scoring = {
    'acc': 'accuracy',
    'prec': 'precision_macro',
    'rec': 'recall_macro',
    'f1': 'f1_macro',
    'b_acc': 'balanced_accuracy'
}

# Realizar la validación cruzada
scores = cross_validate(clf_rf, X, y, scoring=scoring, cv=5, return_train_score=False)
df_scores = pd.DataFrame(scores)
# Calcular los promedios de las métricas de validación cruzada
results = df_scores.mean()
print(results)

# Configurar la validación cruzada estratificada para la curva ROC
cv = StratifiedKFold(n_splits=5)

# Listas para almacenar métricas de cada pliegue
thrs = []
tprs = []
fprs = []
aucs = []

# Calcular la curva ROC para cada pliegue
fig, ax = plt.subplots(figsize=(6, 6))

for fold, (train, test) in tqdm(enumerate(cv.split(X, y)), total=cv.get_n_splits(), desc='Calculando curva ROC'):
    clf_rf.fit(X[train], y[train])
    # Verificar si el clasificador tiene el atributo `predict_proba`
    if hasattr(clf_rf, "predict_proba"):
        y_pred_prob = clf_rf.predict_proba(X[test])[:, 1]
        fpr, tpr, thresholds = roc_curve(y[test], y_pred_prob)
        roc_auc = auc(fpr, tpr)
        aucs.append(roc_auc)

        # Encuentra el umbral óptimo y almacena los valores correspondientes
        gmean = np.sqrt(tpr * (1 - fpr))
        index = np.argmax(gmean)
        thrs.append(thresholds[index])
        tprs.append(tpr[index])
        fprs.append(fpr[index])

        # Graficar la curva ROC para este pliegue
        ax.plot(fpr, tpr, lw=2, alpha=0.3, label=f'Fold {fold} (AUC = {roc_auc:.2f})')

# Graficar la línea de suerte
ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)

# Configuración del gráfico
ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], title="Curva ROC para Random Forest")
ax.legend(loc="lower right")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.show()

# Imprimir los AUC promedios
print(f'AUC promedio: {np.mean(aucs):.4f}')
# Imprimir los umbrales óptimos, TPR y FPR promedio
print(f'Umbrales óptimos para cada fold: {thrs}')
print(f'TPR promedio: {np.mean(tprs):.4f}')
print(f'FPR promedio: {np.mean(fprs):.4f}')

test_image = plt.imread('/content/drive/MyDrive/Central.jpg')
test_image = color.rgb2gray(test_image)
test_image = rescale(test_image,0.5)
test_image.shape

# Visualizamos la imagen
# Buscamos la escala de los rostros
fig, ax = plt.subplots()
ax.imshow(test_image, cmap='gray')

scale = 0.6
Ni, Nj = (int(scale * s) for s in size)

ax.add_patch(plt.Rectangle((0, 0), Nj, Ni, edgecolor='red', alpha=1, lw=1, facecolor='none'))
plt.show()

# Utiliza la función de ventana deslizante en una imagen de prueba.
# zip(*...) toma las tuplas generadas y las descompone en índices y parches.
indices, patches = zip(*sliding_window(test_image, scale=scale))

# Calcula las características HOG para cada parche y las almacena en un array.
patches_hog = np.array([feature.hog(patch,
                                    orientations=orientations,
                                    pixels_per_cell=pixels_per_cell,
                                    cells_per_block=cells_per_block) for patch in patches])

# Muestra la forma del array de características HOG.
patches_hog.shape

# Predicción
clf_rf1 = load('random_forest_model1.pkl')
labels = clf_rf1.predict(patches_hog).astype(int)
labels.sum()

Ni, Nj = (int(scale*s) for s in size)
indices = np.array(indices)
detecciones = indices[labels == 1]
detecciones = non_max_suppression(np.array(detecciones),Ni,Nj, 0.3)

# Visualizamos las detecciones
fig, ax = plt.subplots()
ax.imshow(test_image, cmap='gray')
ax.axis('off')

for i, j in detecciones:
    ax.add_patch(plt.Rectangle((j, i), Nj, Ni, edgecolor='red',
                               alpha=1, lw=1, facecolor='none'))

plt.savefig('test_centralRandom1.png')

"""## 5) Random Forest II

"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicializar el modelo Random Forest
clf_rf2 = RandomForestClassifier(n_estimators=100, random_state=42)
# Entrenar el modelo
clf_rf2.fit(X_train, y_train)
dump(clf_rf2, 'random_forest_model2.pkl')

# Evaluar el modelo en el conjunto de prueba
y_pred = clf_rf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

# Diccionario de métricas para la validación cruzada
scoring = {
    'acc': 'accuracy',
    'prec': 'precision_macro',
    'rec': 'recall_macro',
    'f1': 'f1_macro',
    'b_acc': 'balanced_accuracy'
}

# Realizar la validación cruzada
scores = cross_validate(clf_rf, X, y, scoring=scoring, cv=5, return_train_score=False)
df_scores = pd.DataFrame(scores)
# Calcular los promedios de las métricas de validación cruzada
results = df_scores.mean()
print(results)

# Configurar la validación cruzada estratificada para la curva ROC
cv = StratifiedKFold(n_splits=5)

# Listas para almacenar métricas de cada pliegue
thrs = []
tprs = []
fprs = []
aucs = []

# Calcular la curva ROC para cada pliegue
fig, ax = plt.subplots(figsize=(6, 6))

for fold, (train, test) in tqdm(enumerate(cv.split(X, y)), total=cv.get_n_splits(), desc='Calculando curva ROC'):
    clf_rf.fit(X[train], y[train])
    # Verificar si el clasificador tiene el atributo `predict_proba`
    if hasattr(clf_rf, "predict_proba"):
        y_pred_prob = clf_rf.predict_proba(X[test])[:, 1]
        fpr, tpr, thresholds = roc_curve(y[test], y_pred_prob)
        roc_auc = auc(fpr, tpr)
        aucs.append(roc_auc)

        # Encuentra el umbral óptimo y almacena los valores correspondientes
        gmean = np.sqrt(tpr * (1 - fpr))
        index = np.argmax(gmean)
        thrs.append(thresholds[index])
        tprs.append(tpr[index])
        fprs.append(fpr[index])

        # Graficar la curva ROC para este pliegue
        ax.plot(fpr, tpr, lw=2, alpha=0.3, label=f'Fold {fold} (AUC = {roc_auc:.2f})')

# Graficar la línea de suerte
ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)

# Configuración del gráfico
ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], title="Curva ROC para Random Forest")
ax.legend(loc="lower right")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.show()

# Imprimir los AUC promedios
print(f'AUC promedio: {np.mean(aucs):.4f}')
# Imprimir los umbrales óptimos, TPR y FPR promedio
print(f'Umbrales óptimos para cada fold: {thrs}')
print(f'TPR promedio: {np.mean(tprs):.4f}')
print(f'FPR promedio: {np.mean(fprs):.4f}')

test_image = plt.imread('/content/drive/MyDrive/Central.jpg')
test_image = color.rgb2gray(test_image)
test_image = rescale(test_image,0.5)
test_image.shape

# Visualizamos la imagen
# Buscamos la escala de los rostros
fig, ax = plt.subplots()
ax.imshow(test_image, cmap='gray')

scale = 0.6
Ni, Nj = (int(scale * s) for s in size)

ax.add_patch(plt.Rectangle((0, 0), Nj, Ni, edgecolor='red', alpha=1, lw=1, facecolor='none'))
plt.show()

# Utiliza la función de ventana deslizante en una imagen de prueba.
# zip(*...) toma las tuplas generadas y las descompone en índices y parches.
indices, patches = zip(*sliding_window(test_image, scale=scale))

# Calcula las características HOG para cada parche y las almacena en un array.
patches_hog = np.array([feature.hog(patch,
                                    orientations=orientations,
                                    pixels_per_cell=pixels_per_cell,
                                    cells_per_block=cells_per_block) for patch in patches])

# Muestra la forma del array de características HOG.
patches_hog.shape

# Predicción
clf_rf2 = load('random_forest_model2.pkl')
labels = clf_rf2.predict(patches_hog).astype(int)
labels.sum()

Ni, Nj = (int(scale*s) for s in size)
indices = np.array(indices)
detecciones = indices[labels == 1]
detecciones = non_max_suppression(np.array(detecciones),Ni,Nj, 0.3)

# Visualizamos las detecciones
fig, ax = plt.subplots()
ax.imshow(test_image, cmap='gray')
ax.axis('off')

for i, j in detecciones:
    ax.add_patch(plt.Rectangle((j, i), Nj, Ni, edgecolor='red',
                               alpha=1, lw=1, facecolor='none'))

plt.savefig('test_centralRandom2.png')

"""## 6) ADA Boosting

"""

from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicializar el modelo AdaBoost con DecisionTreeClassifier como base y 200 estimadores
base_estimator = DecisionTreeClassifier(max_depth=1)  # Base estimator
clf_ada = AdaBoostClassifier(
    estimator=base_estimator,
    n_estimators=200,
    learning_rate=1.5,
    random_state=42
)


# Entrenar el modelo AdaBoost
clf_ada.fit(X_train, y_train)
dump(clf_ada, 'ada_model.pkl')

# Evaluar el modelo en el conjunto de prueba
y_pred = clf_ada.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

# Realizar la validación cruzada
scores = cross_validate(clf_ada, X, y, scoring=scoring, cv=5, return_train_score=False)
df_scores = pd.DataFrame(scores)

# Calcular los promedios de las métricas de validación cruzada
results = df_scores.mean()
print(results)

# Configurar la validación cruzada estratificada para la curva ROC
cv = StratifiedKFold(n_splits=5)

# Listas para almacenar métricas de cada pliegue
thrs = []
tprs = []
fprs = []
aucs = []

# Calcular la curva ROC para cada pliegue
fig, ax = plt.subplots(figsize=(6, 6))

for fold, (train, test) in tqdm(enumerate(cv.split(X, y)), total=cv.get_n_splits(), desc='Calculando curva ROC'):
    clf_ada.fit(X[train], y[train])
    y_pred_prob = clf_ada.predict_proba(X[test])[:, 1]
    fpr, tpr, thresholds = roc_curve(y[test], y_pred_prob)
    roc_auc = auc(fpr, tpr)
    aucs.append(roc_auc)

    # Encuentra el umbral óptimo y almacena los valores correspondientes
    gmean = np.sqrt(tpr * (1 - fpr))
    index = np.argmax(gmean)
    thrs.append(thresholds[index])
    tprs.append(tpr[index])
    fprs.append(fpr[index])

    # Graficar la curva ROC para este pliegue
    ax.plot(fpr, tpr, lw=2, alpha=0.3, label=f'Fold {fold} (AUC = {roc_auc:.2f})')

# Graficar la línea de suerte
ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)

# Configuración del gráfico
ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], title="Curva ROC para AdaBoost")
ax.legend(loc="lower right")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.show()

# Imprimir los AUC promedios y demás métricas
print(f'AUC promedio: {np.mean(aucs):.4f}')
print(f'Umbrales óptimos para cada fold: {thrs}')
print(f'TPR promedio: {np.mean(tprs):.4f}')
print(f'FPR promedio: {np.mean(fprs):.4f}')

test_image = plt.imread('/content/drive/MyDrive/Central.jpg')
test_image = color.rgb2gray(test_image)
test_image = rescale(test_image,0.5)
test_image.shape

# Predicción
clf_ada = load('ada_model.pkl')
labels = clf_ada.predict(patches_hog).astype(int)
labels.sum()

Ni, Nj = (int(scale*s) for s in size)
indices = np.array(indices)
detecciones = indices[labels == 1]
detecciones = non_max_suppression(np.array(detecciones),Ni,Nj, 0.3)

# Visualizamos las detecciones
fig, ax = plt.subplots()
ax.imshow(test_image, cmap='gray')
ax.axis('off')

for i, j in detecciones:
    ax.add_patch(plt.Rectangle((j, i), Nj, Ni, edgecolor='red',
                               alpha=1, lw=1, facecolor='none'))

plt.savefig('test_centralAda.png')

"""## 9) ADA BOOST 2

"""

from sklearn.model_selection import train_test_split
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicializar el modelo AdaBoost con DecisionTreeClassifier como base y 200 estimadores
base_estimator = DecisionTreeClassifier(max_depth=6)  # Base estimator
clf_ada = AdaBoostClassifier(
    estimator=base_estimator,
    n_estimators=200,
    learning_rate=1.5,
    random_state=42
)


# Entrenar el modelo AdaBoost
clf_ada.fit(X_train, y_train)
dump(clf_ada, 'ada2_model.pkl')

# Evaluar el modelo en el conjunto de prueba
y_pred = clf_ada.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

# Realizar la validación cruzada
scores = cross_validate(clf_ada, X, y, scoring=scoring, cv=5, return_train_score=False)
df_scores = pd.DataFrame(scores)

# Calcular los promedios de las métricas de validación cruzada
results = df_scores.mean()
print(results)

# Configurar la validación cruzada estratificada para la curva ROC
cv = StratifiedKFold(n_splits=5)

# Listas para almacenar métricas de cada pliegue
thrs = []
tprs = []
fprs = []
aucs = []

# Calcular la curva ROC para cada pliegue
fig, ax = plt.subplots(figsize=(6, 6))

for fold, (train, test) in tqdm(enumerate(cv.split(X, y)), total=cv.get_n_splits(), desc='Calculando curva ROC'):
    clf_ada.fit(X[train], y[train])
    y_pred_prob = clf_ada.predict_proba(X[test])[:, 1]
    fpr, tpr, thresholds = roc_curve(y[test], y_pred_prob)
    roc_auc = auc(fpr, tpr)
    aucs.append(roc_auc)

    # Encuentra el umbral óptimo y almacena los valores correspondientes
    gmean = np.sqrt(tpr * (1 - fpr))
    index = np.argmax(gmean)
    thrs.append(thresholds[index])
    tprs.append(tpr[index])
    fprs.append(fpr[index])

    # Graficar la curva ROC para este pliegue
    ax.plot(fpr, tpr, lw=2, alpha=0.3, label=f'Fold {fold} (AUC = {roc_auc:.2f})')

# Graficar la línea de suerte
ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)

# Configuración del gráfico
ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], title="Curva ROC para AdaBoost")
ax.legend(loc="lower right")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.show()

# Imprimir los AUC promedios y demás métricas
print(f'AUC promedio: {np.mean(aucs):.4f}')
print(f'Umbrales óptimos para cada fold: {thrs}')
print(f'TPR promedio: {np.mean(tprs):.4f}')
print(f'FPR promedio: {np.mean(fprs):.4f}')

test_image = plt.imread('/content/drive/MyDrive/Central.jpg')
test_image = color.rgb2gray(test_image)
test_image = rescale(test_image,0.5)
test_image.shape

# Predicción
clf_ada = load('ada2_model.pkl')
labels = clf_ada.predict(patches_hog).astype(int)
labels.sum()

Ni, Nj = (int(scale*s) for s in size)
indices = np.array(indices)
detecciones = indices[labels == 1]
detecciones = non_max_suppression(np.array(detecciones),Ni,Nj, 0.3)

# Visualizamos las detecciones
fig, ax = plt.subplots()
ax.imshow(test_image, cmap='gray')
ax.axis('off')

for i, j in detecciones:
    ax.add_patch(plt.Rectangle((j, i), Nj, Ni, edgecolor='red',
                               alpha=1, lw=1, facecolor='none'))

plt.savefig('test_centralAda.png')

"""## 7) RED NEURONAL"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear el modelo de red neuronal
model = Sequential()
model.add(Dense(64, input_shape=(X_train.shape[1],), activation='relu'))  # Capa de entrada y primera capa oculta
model.add(Dense(32, activation='relu'))  # Segunda capa oculta
model.add(Dense(1, activation='sigmoid'))  # Capa de salida para clasificación binaria

# Compilar el modelo
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Entrenar el modelo
history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)
model.save('redesNeuronales1.h5')

# Evaluar el modelo en el conjunto de prueba
y_pred = model.predict(X_test)
y_pred_classes = (y_pred > 0.5).astype("int32")

print("Evaluación en el conjunto de prueba:")
print(confusion_matrix(y_test, y_pred_classes))
print(classification_report(y_test, y_pred_classes))

# Opcional: Visualizar el proceso de entrenamiento
import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Precisión del modelo')
plt.ylabel('Precisión')
plt.xlabel('Época')
plt.legend(['Entrenamiento', 'Validación'], loc='upper left')
plt.show()

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt



# Obtener las probabilidades predichas para la clase positiva
y_pred_probs = model.predict(X_test)

# Calcular FPR, TPR y umbrales para la curva ROC
fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)
roc_auc = auc(fpr, tpr)

# Graficar la curva ROC
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()

test_image = plt.imread('/content/drive/MyDrive/Central.jpg')
test_image = color.rgb2gray(test_image)
test_image = rescale(test_image,0.5)
test_image.shape

# Predicción
from tensorflow.keras.models import load_model


modelo_cargado = load_model('redesNeuronales1.h5')
# Asumiendo que 'patches_hog' contiene tus datos preprocesados
y_pred = modelo_cargado.predict(patches_hog)
labels = (y_pred > 0.5).astype(int)  # Para clasificación binaria
total_labels = labels.sum()
print(total_labels)

# Asumiendo que tienes las variables test_image, scale, y size definidas correctamente
Ni, Nj = (int(scale * s) for s in size)

# Asumiendo que 'labels' contiene las predicciones de tu modelo de red neuronal
indices = np.array(indices)
detecciones = indices[labels.flatten() == 1]  # Aplanar labels si es necesario
detecciones = non_max_suppression(detecciones, Ni, Nj, 0.3)

# Visualizar las detecciones
fig, ax = plt.subplots()
ax.imshow(test_image, cmap='gray')
ax.axis('off')

for i, j in detecciones:
    ax.add_patch(plt.Rectangle((j, i), Nj, Ni, edgecolor='red',
                               alpha=1, lw=1, facecolor='none'))

plt.savefig('test_centralRedesNeuronales1.png')

"""## 8) Red Neuronal 2
 Neuronales 2
"""

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear el segundo modelo de red neuronal
model_2 = Sequential()

# Capa de entrada y primera capa oculta con más neuronas
model_2.add(Dense(128, input_shape=(X_train.shape[1],), activation='relu'))

# Añadir Dropout para reducir el sobreajuste
model_2.add(Dropout(0.5))

# Segunda capa oculta
model_2.add(Dense(64, activation='relu'))

# Tercera capa oculta
model_2.add(Dense(32, activation='relu'))

# Capa de salida para clasificación binaria
model_2.add(Dense(1, activation='sigmoid'))

# Compilar el modelo con un optimizador diferente
model_2.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])

# Entrenar el modelo
history_2 = model_2.fit(X_train, y_train, epochs=15, batch_size=128, validation_split=0.2)
model.save('redesNeuronales2.h5')

# Evaluar el modelo en el conjunto de prueba
y_pred_2 = model_2.predict(X_test)
y_pred_classes_2 = (y_pred_2 > 0.5).astype("int32")

print("Evaluación en el conjunto de prueba para el segundo modelo:")
print(confusion_matrix(y_test, y_pred_classes_2))
print(classification_report(y_test, y_pred_classes_2))

import matplotlib.pyplot as plt

plt.plot(history_2.history['accuracy'])
plt.plot(history_2.history['val_accuracy'])
plt.title('Precisión del segundo modelo')
plt.ylabel('Precisión')
plt.xlabel('Época')
plt.legend(['Entrenamiento', 'Validación'], loc='upper left')
plt.show()

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt



# Obtener las probabilidades predichas para la clase positiva
y_pred_probs = model_2.predict(X_test)

# Calcular FPR, TPR y umbrales para la curva ROC
fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)
roc_auc = auc(fpr, tpr)

# Graficar la curva ROC
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Curva ROC')
plt.legend(loc="lower right")
plt.show()

test_image = plt.imread('/content/drive/MyDrive/Central.jpg')
test_image = color.rgb2gray(test_image)
test_image = rescale(test_image,0.5)
test_image.shape

# Predicción
from tensorflow.keras.models import load_model


modelo_cargado2 = load_model('redesNeuronales2.h5')
# Asumiendo que 'patches_hog' contiene tus datos preprocesados
y_pred = modelo_cargado2.predict(patches_hog)
labels2 = (y_pred > 0.5).astype(int)  # Para clasificación binaria
total_labels2 = labels2.sum()
print(total_labels2)

# Asumiendo que tienes las variables test_image, scale, y size definidas correctamente
Ni, Nj = (int(scale * s) for s in size)

# Asumiendo que 'labels' contiene las predicciones de tu modelo de red neuronal
indices = np.array(indices)
detecciones2 = indices[labels2.flatten() == 1]  # Aplanar labels si es necesario
detecciones2 = non_max_suppression(detecciones2, Ni, Nj, 0.3)

# Visualizar las detecciones
fig, ax = plt.subplots()
ax.imshow(test_image, cmap='gray')
ax.axis('off')

for i, j in detecciones2:
    ax.add_patch(plt.Rectangle((j, i), Nj, Ni, edgecolor='red',
                               alpha=1, lw=1, facecolor='none'))

plt.savefig('test_centralRedesNeuronales2.png')

"""## 10) ADA BOOST con Regresión Logistica"""

from sklearn.ensemble import AdaBoostClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm

# Asumiendo que X e y ya están definidos y son tus datos y etiquetas

# Dividir los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Inicializar el modelo AdaBoost con LogisticRegression como base y 100 estimadores
base_estimator = LogisticRegression()  # Base estimator
clf_ada = AdaBoostClassifier(
    estimator=base_estimator,
    n_estimators=100,
    learning_rate=1,
    random_state=42
)

# Entrenar el modelo AdaBoost
clf_ada.fit(X_train, y_train)
dump(clf_ada, 'ada_logistic_model.pkl')

# Evaluar el modelo en el conjunto de prueba
y_pred = clf_ada.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

# Realizar la validación cruzada
scoring = ['accuracy', 'precision', 'recall', 'f1']  # Asegúrate de definir las métricas que deseas usar
scores = cross_validate(clf_ada, X, y, scoring=scoring, cv=5, return_train_score=False)
df_scores = pd.DataFrame(scores)
# Calcular los promedios de las métricas de validación cruzada
results = df_scores.mean()
print(results)

# Configurar la validación cruzada estratificada para la curva ROC
cv = StratifiedKFold(n_splits=5)

# Listas para almacenar métricas de cada pliegue
thrs = []
tprs = []
fprs = []
aucs = []

# Calcular la curva ROC para cada pliegue
fig, ax = plt.subplots(figsize=(6, 6))

for fold, (train, test) in tqdm(enumerate(cv.split(X, y)), total=cv.get_n_splits(), desc='Calculando curva ROC'):
    clf_ada.fit(X[train], y[train])
    y_pred_prob = clf_ada.predict_proba(X[test])[:, 1]
    fpr, tpr, thresholds = roc_curve(y[test], y_pred_prob)
    roc_auc = auc(fpr, tpr)
    aucs.append(roc_auc)

    # Encuentra el umbral óptimo y almacena los valores correspondientes
    gmean = np.sqrt(tpr * (1 - fpr))
    index = np.argmax(gmean)
    thrs.append(thresholds[index])
    tprs.append(tpr[index])
    fprs.append(fpr[index])

    # Graficar la curva ROC para este pliegue
    ax.plot(fpr, tpr, lw=2, alpha=0.3, label=f'Fold {fold} (AUC = {roc_auc:.2f})')

# Graficar la línea de suerte
ax.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)

# Configuración del gráfico
ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], title="Curva ROC para AdaBoost con Logistic Regression")
ax.legend(loc="lower right")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.show()

# Imprimir los AUC promedios y demás métricas
print(f'AUC promedio: {np.mean(aucs):.4f}')
print(f'Umbrales óptimos para cada fold: {thrs}')
print(f'TPR promedio: {np.mean(tprs):.4f}')
print(f'FPR promedio: {np.mean(fprs):.4f}')

# Predicción
clf_rf = load('ada_logistic_model.pkl')
labels = clf_rf.predict(patches_hog).astype(int)
labels.sum()

Ni, Nj = (int(scale*s) for s in size)
indices = np.array(indices)
detecciones = indices[labels == 1]
detecciones = non_max_suppression(np.array(detecciones),Ni,Nj, 0.3)

# Visualizamos las detecciones
fig, ax = plt.subplots()
ax.imshow(test_image, cmap='gray')
ax.axis('off')

for i, j in detecciones:
    ax.add_patch(plt.Rectangle((j, i), Nj, Ni, edgecolor='red',
                               alpha=1, lw=1, facecolor='none'))

plt.savefig('test_centralAdaBoostConLogisticReg.png')